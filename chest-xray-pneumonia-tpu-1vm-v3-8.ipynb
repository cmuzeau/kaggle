{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Chest X-ray pneumonia](https://www.kaggle.com/datasets/paultimothymooney/chest-xray-pneumonia)\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-05T15:44:40.466360Z",
     "iopub.status.busy": "2023-01-05T15:44:40.465221Z",
     "iopub.status.idle": "2023-01-05T15:44:40.471733Z",
     "shell.execute_reply": "2023-01-05T15:44:40.470812Z",
     "shell.execute_reply.started": "2023-01-05T15:44:40.466318Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "import torch_xla.core.xla_model as xm\n",
    "\n",
    "start = time.time()\n",
    "device = xm.xla_device()\n",
    "print(f\"{time.time()-start:.0f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-05T15:44:45.301065Z",
     "iopub.status.busy": "2023-01-05T15:44:45.300356Z",
     "iopub.status.idle": "2023-01-05T15:44:45.306275Z",
     "shell.execute_reply": "2023-01-05T15:44:45.305290Z",
     "shell.execute_reply.started": "2023-01-05T15:44:45.301031Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.11'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch_xla\n",
    "# latest: '1.13'\n",
    "# pinned: '1.11'\n",
    "torch_xla.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-01-04T10:05:17.990713Z",
     "iopub.status.busy": "2023-01-04T10:05:17.990401Z",
     "iopub.status.idle": "2023-01-04T10:05:36.368064Z",
     "shell.execute_reply": "2023-01-04T10:05:36.366753Z",
     "shell.execute_reply.started": "2023-01-04T10:05:17.990646Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.8.15 (default, Oct 14 2022, 00:19:58) \n",
      "[GCC 10.2.1 20210110]\n",
      "torch.__version__='1.11.0+cu102'\n",
      "torchvision.__version__='0.12.0+cu102'\n",
      "torch_xla.__version__='1.11'\n",
      "os.environ['KAGGLE_DOCKER_IMAGE']='gcr.io/kaggle-gpu-images/python-tpuvm'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[percpu.cc : 560] RAW: rseq syscall failed with errno 1\n"
     ]
    }
   ],
   "source": [
    "from   collections import OrderedDict\n",
    "import os\n",
    "assert 'ISTPUVM' in os.environ, \"Select TPU 1VM v3-8 in Settings > Accelerator from the right panel.\"\n",
    "from   pathlib import Path\n",
    "import sys\n",
    "\n",
    "from   IPython.display import clear_output\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from   torch.utils.data import DataLoader\n",
    "from   torch.utils.data.distributed import DistributedSampler\n",
    "import torchvision\n",
    "from   torchvision import transforms as T, datasets\n",
    "from   torchvision.models import densenet121\n",
    "import torch_xla\n",
    "import torch_xla.core.xla_model as xm\n",
    "import torch_xla.distributed.parallel_loader as pl\n",
    "import torch_xla.distributed.xla_multiprocessing as xmp\n",
    "import torch_xla.test.test_utils as test_utils\n",
    "\n",
    "print(sys.version)\n",
    "print(f\"{torch.__version__=}\")\n",
    "print(f\"{torchvision.__version__=}\")\n",
    "print(f\"{torch_xla.__version__=}\")\n",
    "print(f\"{os.environ['KAGGLE_DOCKER_IMAGE']=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-31T17:38:48.434130Z",
     "iopub.status.busy": "2022-12-31T17:38:48.433664Z",
     "iopub.status.idle": "2022-12-31T17:47:18.716403Z",
     "shell.execute_reply": "2022-12-31T17:47:18.715131Z",
     "shell.execute_reply.started": "2022-12-31T17:38:48.434098Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-31 17:38:48.779569: E tensorflow/core/framework/op_kernel.cc:1676] OpKernel ('op: \"TPURoundRobin\" device_type: \"CPU\"') for unknown op: TPURoundRobin\n",
      "2022-12-31 17:38:48.779648: E tensorflow/core/framework/op_kernel.cc:1676] OpKernel ('op: \"TpuHandleToProtoKey\" device_type: \"CPU\"') for unknown op: TpuHandleToProtoKey\n",
      "2022-12-31 17:38:57.791847: E tensorflow/core/framework/op_kernel.cc:1676] OpKernel ('op: \"TPURoundRobin\" device_type: \"CPU\"') for unknown op: TPURoundRobin\n",
      "2022-12-31 17:38:57.791937: E tensorflow/core/framework/op_kernel.cc:1676] OpKernel ('op: \"TpuHandleToProtoKey\" device_type: \"CPU\"') for unknown op: TpuHandleToProtoKey\n",
      "2022-12-31 17:38:58.237731: E tensorflow/core/framework/op_kernel.cc:1676] OpKernel ('op: \"TPURoundRobin\" device_type: \"CPU\"') for unknown op: TPURoundRobin\n",
      "2022-12-31 17:38:58.237839: E tensorflow/core/framework/op_kernel.cc:1676] OpKernel ('op: \"TpuHandleToProtoKey\" device_type: \"CPU\"') for unknown op: TpuHandleToProtoKey\n",
      "2022-12-31 17:38:58.395490: E tensorflow/core/framework/op_kernel.cc:1676] OpKernel ('op: \"TPURoundRobin\" device_type: \"CPU\"') for unknown op: TPURoundRobin\n",
      "2022-12-31 17:38:58.395579: E tensorflow/core/framework/op_kernel.cc:1676] OpKernel ('op: \"TpuHandleToProtoKey\" device_type: \"CPU\"') for unknown op: TpuHandleToProtoKey\n",
      "2022-12-31 17:38:58.477909: E tensorflow/core/framework/op_kernel.cc:1676] OpKernel ('op: \"TPURoundRobin\" device_type: \"CPU\"') for unknown op: TPURoundRobin\n",
      "2022-12-31 17:38:58.477996: E tensorflow/core/framework/op_kernel.cc:1676] OpKernel ('op: \"TpuHandleToProtoKey\" device_type: \"CPU\"') for unknown op: TpuHandleToProtoKey\n",
      "2022-12-31 17:38:58.746916: E tensorflow/core/framework/op_kernel.cc:1676] OpKernel ('op: \"TPURoundRobin\" device_type: \"CPU\"') for unknown op: TPURoundRobin\n",
      "2022-12-31 17:38:58.747019: E tensorflow/core/framework/op_kernel.cc:1676] OpKernel ('op: \"TpuHandleToProtoKey\" device_type: \"CPU\"') for unknown op: TpuHandleToProtoKey\n",
      "2022-12-31 17:38:58.890097: E tensorflow/core/framework/op_kernel.cc:1676] OpKernel ('op: \"TPURoundRobin\" device_type: \"CPU\"') for unknown op: TPURoundRobin\n",
      "2022-12-31 17:38:58.890204: E tensorflow/core/framework/op_kernel.cc:1676] OpKernel ('op: \"TpuHandleToProtoKey\" device_type: \"CPU\"') for unknown op: TpuHandleToProtoKey\n",
      "2022-12-31 17:39:05.175400: E tensorflow/core/framework/op_kernel.cc:1676] OpKernel ('op: \"TPURoundRobin\" device_type: \"CPU\"') for unknown op: TPURoundRobin\n",
      "2022-12-31 17:39:05.175507: E tensorflow/core/framework/op_kernel.cc:1676] OpKernel ('op: \"TpuHandleToProtoKey\" device_type: \"CPU\"') for unknown op: TpuHandleToProtoKey\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch= 1] train_loss=0.592125 | val_loss=0.723253 | val_accuracy=50.00%\n",
      "[epoch= 2] train_loss=0.500733 | val_loss=0.611433 | val_accuracy=50.00%\n",
      "[epoch= 3] train_loss=0.415963 | val_loss=1.341232 | val_accuracy=62.50%\n",
      "[epoch= 4] train_loss=0.387049 | val_loss=2.135455 | val_accuracy=62.50%\n",
      "[epoch= 5] train_loss=0.354496 | val_loss=2.421763 | val_accuracy=68.75%\n",
      "[epoch= 6] train_loss=0.316311 | val_loss=1.583380 | val_accuracy=62.50%\n",
      "[epoch= 7] train_loss=0.290943 | val_loss=0.974968 | val_accuracy=62.50%\n",
      "[epoch= 8] train_loss=0.278477 | val_loss=2.553512 | val_accuracy=56.25%\n",
      "[epoch= 9] train_loss=0.239074 | val_loss=2.897424 | val_accuracy=56.25%\n",
      "[epoch=10] train_loss=0.294546 | val_loss=1.149176 | val_accuracy=31.25%\n",
      "[epoch=11] train_loss=0.292732 | val_loss=1.059300 | val_accuracy=68.75%\n",
      "[epoch=12] train_loss=0.204917 | val_loss=24.127287 | val_accuracy=50.00%\n",
      "[epoch=13] train_loss=0.228277 | val_loss=2.481347 | val_accuracy=56.25%\n",
      "[epoch=14] train_loss=0.271624 | val_loss=5.311549 | val_accuracy=56.25%\n",
      "[epoch=15] train_loss=0.196949 | val_loss=0.818701 | val_accuracy=62.50%\n",
      "[epoch=16] train_loss=0.194449 | val_loss=0.771003 | val_accuracy=50.00%\n",
      "[epoch=17] train_loss=0.197051 | val_loss=3.113962 | val_accuracy=50.00%\n",
      "[epoch=18] train_loss=0.173841 | val_loss=0.992332 | val_accuracy=43.75%\n",
      "[epoch=19] train_loss=0.272857 | val_loss=2.848061 | val_accuracy=56.25%\n",
      "[epoch=20] train_loss=0.190205 | val_loss=4.484068 | val_accuracy=50.00%\n"
     ]
    }
   ],
   "source": [
    "data_path = Path('../input/chest-xray-pneumonia/chest_xray/chest_xray')\n",
    "\n",
    "# https://pytorch.org/xla/release/1.13/index.html#torch_xla.distributed.xla_multiprocessing.MpSerialExecutor\n",
    "# https://discuss.pytorch.org/t/what-does-xmp-mpserialexecutor-really-do/96150\n",
    "# MX = xmp.MpModelWrapper(model)\n",
    "\n",
    "train_transform = T.Compose([\n",
    "    T.Resize((224, 224), antialias=True),\n",
    "    T.RandomAffine(degrees=15, translate=(0.2, 0.2), scale=(0.5, 1.5)),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "])\n",
    "\n",
    "eval_transform = T.Compose([\n",
    "    T.Resize((224,224), antialias=True),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "])\n",
    "\n",
    "train_data = datasets.ImageFolder(root=data_path/\"train\", transform=train_transform)\n",
    "val_data = datasets.ImageFolder(root=data_path/\"val\", transform=eval_transform)\n",
    "\n",
    "model = densenet121()\n",
    "model.classifier = nn.Sequential(OrderedDict([\n",
    "    ('fcl1', nn.Linear(1024,256)),\n",
    "    ('dp1', nn.Dropout(0.3)),\n",
    "    ('r1', nn.ReLU()),\n",
    "    ('fcl2', nn.Linear(256,32)),\n",
    "    ('dp2', nn.Dropout(0.3)),\n",
    "    ('r2', nn.ReLU()),\n",
    "    ('fcl3', nn.Linear(32,2)),\n",
    "    ('out', nn.LogSoftmax(dim=1)),\n",
    "]))\n",
    "\n",
    "def _mp_fn(index):\n",
    "    global model\n",
    "    \n",
    "    train_sampler = DistributedSampler(\n",
    "        train_data,\n",
    "        num_replicas=xm.xrt_world_size(),\n",
    "        rank=xm.get_ordinal(),\n",
    "        shuffle=True,\n",
    "    )\n",
    "    train_loader = DataLoader(\n",
    "        train_data,\n",
    "        batch_size=128,\n",
    "        sampler=train_sampler,\n",
    "        drop_last=False,\n",
    "        num_workers=8,\n",
    "    )\n",
    "    \n",
    "    val_sampler = DistributedSampler(\n",
    "        val_data,\n",
    "        num_replicas=xm.xrt_world_size(),\n",
    "        rank=xm.get_ordinal(),\n",
    "        shuffle=False\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        val_data,\n",
    "        batch_size=8,\n",
    "        sampler=val_sampler,\n",
    "        drop_last=False,\n",
    "        num_workers=8,\n",
    "    )\n",
    "\n",
    "    device = xm.xla_device()\n",
    "    train_device_loader = pl.MpDeviceLoader(train_loader, device)\n",
    "    val_device_loader = pl.MpDeviceLoader(val_loader, device)\n",
    "    \n",
    "    # model = MX.to(device)\n",
    "    model.to(device)\n",
    "    loss_fn = nn.NLLLoss()\n",
    "    optimizer = optim.Adadelta(model.parameters())\n",
    "    \n",
    "    epochs = 20\n",
    "    for epoch in range(1, epochs+1):\n",
    "        total = 0\n",
    "        total_samples = 0\n",
    "        model.train()\n",
    "        for step, (data, target) in enumerate(train_device_loader):\n",
    "            # print(f\"\\t[{xm.xla_real_devices([str(device)])[0]}] job started {step}\", flush=True)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = loss_fn(output, target)\n",
    "            loss.backward()\n",
    "            xm.optimizer_step(optimizer)\n",
    "            total += loss.item() * data.size(0)\n",
    "            total_samples += data.size(0)\n",
    "        train_loss_total = xm.mesh_reduce('total', total, np.sum)\n",
    "        train_loss_total_samples = xm.mesh_reduce('total_samples', total_samples, np.sum)\n",
    "        # xm.master_print(f\"[{epoch=:>2}] {device} {xm.xla_real_devices([str(device)])[0]} loss: {accuracy:.6f}\", flush=True)\n",
    "        \n",
    "        total = 0\n",
    "        total_samples = 0\n",
    "        acc = 0\n",
    "        acc_count = 0\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for step, (data, target) in enumerate(val_device_loader):\n",
    "                output = model(data)\n",
    "                loss = loss_fn(output, target)\n",
    "                total += loss.item() * data.size(0)\n",
    "                total_samples += data.size(0)\n",
    "                _, preds = torch.max(output, 1)\n",
    "                acc += (preds == target).float().sum()\n",
    "                acc_count += data.size(0)\n",
    "        val_loss_total = xm.mesh_reduce('total', total, np.sum)\n",
    "        val_loss_total_samples = xm.mesh_reduce('total_samples', total_samples, np.sum)\n",
    "        val_acc = xm.mesh_reduce('acc', acc, np.sum)\n",
    "        val_acc_count = xm.mesh_reduce('acc_count', acc_count, np.sum)\n",
    "        \n",
    "        train_loss = train_loss_total / train_loss_total_samples\n",
    "        val_loss = val_loss_total / val_loss_total_samples\n",
    "        val_accuracy = val_acc / val_acc_count\n",
    "        xm.master_print(f\"[{epoch=:>2}] {train_loss=:.6f} | {val_loss=:.6f} | {val_accuracy=:.2%}\", flush=True)\n",
    "\n",
    "xmp.spawn(_mp_fn, args=(), nprocs=8, start_method='fork')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
