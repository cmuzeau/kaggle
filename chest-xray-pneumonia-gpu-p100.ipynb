{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Chest X-ray pneumonia\n---\nRead [homepage](https://www.kaggle.com/datasets/paultimothymooney/chest-xray-pneumonia) for more information.","metadata":{}},{"cell_type":"markdown","source":"### Imports","metadata":{}},{"cell_type":"code","source":"from   datetime import datetime\nimport os\nfrom   pathlib import Path\nimport time\nimport random\n\nfrom   IPython.display import clear_output\nimport matplotlib.pyplot as plt\nfrom   mpl_toolkits.axes_grid1 import ImageGrid\nimport numpy as np\nimport pandas as pd\nfrom   PIL import Image\nimport plotly.express as px\nimport plotly.graph_objects as go\nfrom   plotly.subplots import make_subplots\n\nimport torch\nassert torch.cuda.device_count() == 1, \"Select GPU P100 in Settings > Accelerator from the right panel.\"\nimport torch.nn as nn\nimport torch.optim as optim\nfrom   torch.utils.data import DataLoader\n\nfrom   torchmetrics.classification import BinaryConfusionMatrix\nfrom   sklearn.metrics import accuracy_score, confusion_matrix\n\nimport torchvision\nfrom   torchvision.datasets import ImageFolder\nimport torchvision.transforms.functional as F\nimport torchvision.transforms as T\nfrom   torchvision.utils import make_grid\nfrom   torchvision.io import read_image, ImageReadMode\nfrom   torchvision.models import efficientnet_b4, densenet121\n\ntorch.use_deterministic_algorithms(True)\n\npd.set_option('max_colwidth', 400)\npd.set_option('display.max_rows', 50)\n\n!nvidia-smi -L","metadata":{"execution":{"iopub.status.busy":"2023-01-04T17:18:33.680533Z","iopub.execute_input":"2023-01-04T17:18:33.680987Z","iopub.status.idle":"2023-01-04T17:18:42.332554Z","shell.execute_reply.started":"2023-01-04T17:18:33.680915Z","shell.execute_reply":"2023-01-04T17:18:42.331362Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"GPU 0: Tesla P100-PCIE-16GB (UUID: GPU-15b1a41c-7f55-77ba-223b-f035b205f63b)\n","output_type":"stream"}]},{"cell_type":"code","source":"def seed_everything(seed=0):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    os.environ['CUBLAS_WORKSPACE_CONFIG'] = \":4096:8\"\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False # ajouter par moi voir si cest tjr deterministique","metadata":{"execution":{"iopub.status.busy":"2023-01-04T17:18:42.335429Z","iopub.execute_input":"2023-01-04T17:18:42.335873Z","iopub.status.idle":"2023-01-04T17:18:42.343930Z","shell.execute_reply.started":"2023-01-04T17:18:42.335833Z","shell.execute_reply":"2023-01-04T17:18:42.341619Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"### Global variables and persistent files","metadata":{}},{"cell_type":"code","source":"data_path = Path('../input/chest-xray-pneumonia/chest_xray/chest_xray/')\n\ncsv_path = Path(\"./chest_xray.csv\")\n\n# create pandas dataframe from the dataset. Process takes around 1 minute to complete so we store the dataframe into a csv file for future use\nif not csv_path.exists():\n    df = pd.DataFrame(((path, *path.parts[-3:], *read_image(str(path)).size()) for path in data_path.rglob(\"*.jpeg\")),\n                      columns=[\"path\", \"subset\", \"label\", \"filename\", \"channel\", \"height\", \"width\"])\n    df[\"aspect_ratio\"] = df[\"width\"] / df[\"height\"]\n    df.to_csv(csv_path, index=False)","metadata":{"execution":{"iopub.status.busy":"2023-01-04T17:18:42.345143Z","iopub.execute_input":"2023-01-04T17:18:42.345772Z","iopub.status.idle":"2023-01-04T17:18:42.354394Z","shell.execute_reply.started":"2023-01-04T17:18:42.345734Z","shell.execute_reply":"2023-01-04T17:18:42.353244Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"### Dataset analysis","metadata":{}},{"cell_type":"code","source":"# load dataset into pandas dataframe\ndf = pd.read_csv(csv_path)","metadata":{"execution":{"iopub.status.busy":"2023-01-04T17:18:42.356891Z","iopub.execute_input":"2023-01-04T17:18:42.357872Z","iopub.status.idle":"2023-01-04T17:18:42.390895Z","shell.execute_reply.started":"2023-01-04T17:18:42.357846Z","shell.execute_reply":"2023-01-04T17:18:42.390072Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# total size of the dataset\nlen(df)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# dataset distribution\ndf.groupby([\"label\", \"subset\"]).size().unstack()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# subset distribution\nwith pd.option_context('display.float_format', \"{:.2%}\".format):\n    print(df[\"subset\"].value_counts(normalize=True))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# class distribution\nwith pd.option_context('display.float_format', \"{:.0%}\".format):\n    print(df[\"label\"].value_counts(normalize=True))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There is a clear imbalance, a lot more samples with PNEUMONIA.","metadata":{}},{"cell_type":"code","source":"# trianing set distribution\nwith pd.option_context('display.float_format', \"{:.0%}\".format):\n    print(df[df[\"subset\"] == \"train\"][\"label\"].value_counts(normalize=True))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Training set distribution similar to whole dataset distribution.","metadata":{}},{"cell_type":"code","source":"# summary statistics on the images\nwith pd.option_context('display.float_format', '{:g}'.format):\n    display(df[[\"height\", \"width\", \"aspect_ratio\"]].describe())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# some images are RGBs but the 3 channels are actually equal\ndf[\"channel\"].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Some images are Grayscale while models require 3 channels as input, this is fixed when loading the image with `read_image` and using parameter `ImageReadMode.RGB`.","metadata":{}},{"cell_type":"code","source":"imgs = [T.Resize((224,224), antialias=True)(read_image(str(path), ImageReadMode.GRAY)) for path in df[\"path\"].sample(n=4)]\ngrid = make_grid(imgs, nrow=4).permute(1,2,0)\nplt.figure(figsize=(25,25))\nplt.imshow(grid)\nplt.axis('off')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Datasets and Dataloader","metadata":{}},{"cell_type":"code","source":"# torch.manual_seed(0)\n# seed = torch.Generator()\n# seed_everything()\n\n# def seed_worker(worker_id):\n#     worker_seed = torch.initial_seed() % 2**32\n#     np.random.seed(worker_seed)\n#     random.seed(worker_seed)\n\n# g = torch.Generator()\n# g.manual_seed(0)\n\ndef check_file(path):\n    try:\n        Image.open(path)\n        return True\n    except:\n        return False\n    \ndef loader(path):\n    return read_image(path, ImageReadMode.RGB)\n\n# https://tcapelle.github.io/pytorch/fastai/2021/02/26/image_resizing.html\ntrain_transform = T.Compose([\n    T.Resize((224, 224), antialias=True),\n#     T.RandomAffine(degrees=15, translate=(.2, .2), scale=(.8, 1.2)),\n    T.ToTensor(),\n#     T.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n    T.Normalize((0.485), (0.229)),\n])\n\neval_transform = T.Compose([\n    T.Resize((224, 224), antialias=True),\n    T.ToTensor(),\n#     T.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n    T.Normalize((0.485), (0.229)),\n])\n\ntrain_data = ImageFolder(\n    root=data_path/\"train\",\n    transform=train_transform,\n#     is_valid_file=check_file,\n#     loader=loader,\n)\ntrain_loader = DataLoader(\n    dataset=train_data,\n    batch_size=32,\n    shuffle=True,\n    num_workers=2,\n#     worker_init_fn=seed_worker,\n#     generator=g,\n)\n\nval_data = ImageFolder(\n    root=data_path/\"val\",\n    transform=eval_transform,\n#     is_valid_file=check_file,\n#     loader=loader,\n)\nval_loader = DataLoader(\n    dataset=val_data,\n    batch_size=8,\n    shuffle=False,\n    num_workers=2,\n)\n\ntest_data = ImageFolder(\n    root=data_path/\"test\",\n    transform=eval_transform,\n#     is_valid_file=check_file,\n#     loader=loader,\n)\ntest_loader = DataLoader(\n    dataset=test_data,\n    batch_size=32,\n    shuffle=False,\n    num_workers=2,\n)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-01-04T17:18:42.392255Z","iopub.execute_input":"2023-01-04T17:18:42.392620Z","iopub.status.idle":"2023-01-04T17:18:45.292729Z","shell.execute_reply.started":"2023-01-04T17:18:42.392586Z","shell.execute_reply":"2023-01-04T17:18:45.291728Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"paths = df[\"path\"].sample(n=24)\ntrans = [train_transform(Image.open(path)) for path in paths]\n\nfig = plt.figure(figsize=(25., 25.))\ngrid = ImageGrid(fig, 111,\n                 nrows_ncols=(3, 8),\n                 axes_pad=.1,\n                 )\n\nfor ax, im in zip(grid, trans):\n    ax.imshow(im.permute((1,2,0)), cmap=\"gray\")\n    ax.axis(\"off\")\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Training","metadata":{}},{"cell_type":"code","source":"seed_everything()\n\ndevice = torch.device(\"cuda\")\n\n# for reproducibility, model must be run with the train loop because \n# the state of the model (weights) is changed after each iteration\nmodel = densenet121()\nmodel.classifier = nn.Sequential(\n    nn.Linear(1024,256),\n    nn.Dropout(0.3),\n    nn.ReLU(),\n    nn.Linear(256,32),\n    nn.Dropout(0.3),\n    nn.ReLU(),\n    nn.Linear(32,2),\n    nn.LogSoftmax(dim=1),\n)\n\n# model = efficientnet_b4()\n# model.classifier = nn.Sequential(\n#     nn.Linear(1792, 1024),\n#     nn.Dropout(0.3),\n#     nn.ReLU(),\n#     nn.Linear(1024, 256),\n#     nn.Dropout(0.3),\n#     nn.ReLU(),\n#     nn.Linear(256, 32),\n#     nn.Dropout(0.3),\n#     nn.ReLU(),\n#     nn.Linear(32,2),\n#     nn.LogSoftmax(dim=1),\n# )\n\nmodel.to(device)\n\nloss_fn = nn.NLLLoss()\nlearning_rate = 1.\noptimizer = optim.Adadelta(model.parameters(), lr=learning_rate)\n\nepochs = 1\ndata = []\nfor epoch in range(1, epochs+1):\n    train_loss = 0\n    nb_train_batches = len(train_loader)\n    train_acc = 0\n    model.train()\n    for batch, (image, target) in enumerate(train_loader, start=1):\n        print(f\"[Epoch {epoch:>2}] Train batch progress: {batch:>3}/{nb_train_batches}\", end='\\r')\n        image = image.to(device)\n        target = target.to(device)\n        output = model(image)\n        loss = loss_fn(output, target)\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        train_loss += loss.item() * image.size(0)\n        _, preds = torch.max(output, 1)\n        train_acc += (preds == target).float().sum().item()\n    \n    val_loss = 0\n    nb_val_batches = len(val_loader)\n    val_acc = 0\n    model.eval()\n    with torch.no_grad():\n        for batch, (image, target) in enumerate(val_loader, start=1):\n            print(f\"[Epoch {epoch:>2}] Val batch progress: {batch:>3}/{nb_val_batches}\", end='\\r')\n            image = image.to(device)\n            target = target.to(device)\n            output = model(image)\n            loss = loss_fn(output, target)\n            val_loss += loss.item() * image.size(0)\n            _, preds = torch.max(output, 1)\n            val_acc += (preds == target).float().sum().item()\n        \n    train_loss /= len(train_loader.dataset)\n    val_loss /= len(val_loader.dataset)\n    train_acc /= len(train_loader.dataset)\n    val_acc /= len(val_loader.dataset)\n    print(f\"[Epoch {epoch:>2}] Train loss: {train_loss:.5f} | Train accuracy: {train_acc:>7.2%} | Val loss: {val_loss:.5f} | Val accuracy: {val_acc:>7.2%}\")\n    data.append([epoch, learning_rate, train_loss, train_acc, val_loss, val_acc])\n    if epoch == 2:\n        break\n\nmodel_name = model._get_name() + '_' + datetime.now().strftime(\"%y%m%d-%H%M%S\")\n\n# save model summary\ndf = pd.DataFrame(data, columns=[\"epoch\", \"learning_rate\", \"train_loss\", \"train_acc\", \"val_loss\", \"val_acc\"])\nPath(\"./runs\").mkdir(exist_ok=True)\ndf.to_csv(\"./runs/\" + model_name + \".csv\", index=False)\n\n# save model\n# https://stackoverflow.com/questions/54746829/pytorch-whats-the-difference-between-state-dict-and-parameters\nPath(\"./models\").mkdir(exist_ok=True)\n# torch.save(model.state_dict(), \"./models/\" + model_name + '_weights_' + '.pth') # parameters only\ntorch.save(model, \"./models/\" + model_name + '.pth')","metadata":{"execution":{"iopub.status.busy":"2023-01-04T17:18:45.294336Z","iopub.execute_input":"2023-01-04T17:18:45.294926Z","iopub.status.idle":"2023-01-04T17:20:42.632420Z","shell.execute_reply.started":"2023-01-04T17:18:45.294890Z","shell.execute_reply":"2023-01-04T17:20:42.631261Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"[Epoch  1] Train loss: 0.27831 | Train accuracy:  88.32% | Val loss: 1.12007 | Val accuracy:  56.25%\n","output_type":"stream"}]},{"cell_type":"markdown","source":"[Epoch  1] Train loss: 0.27831 | Train accuracy:  88.32% | Val loss: 1.12007 | Val accuracy:  56.25%","metadata":{}},{"cell_type":"markdown","source":"### Compare models","metadata":{}},{"cell_type":"code","source":"# available runs\nruns = list(Path(\"./runs\").rglob(\"*.csv\"))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# choose best performing model for test set\nsummary = []\nfor csv in runs:\n    epochs, *_, val_acc = pd.read_csv(csv).iloc[-1]\n    summary.append([csv.stem, int(epochs), val_acc])\npd.DataFrame(summary, columns=[\"model\", \"epochs\", \"val_acc\"])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = make_subplots(rows=2, cols=2,\n                    shared_xaxes=True,\n                    vertical_spacing=0.02)\n\nnb_colors = len(px.colors.qualitative.Plotly)\nfor i, run in enumerate(runs):\n    df = pd.read_csv(run)\n    color = px.colors.qualitative.Plotly[i%nb_colors]\n    fig.add_trace(go.Scatter(x=df[\"epoch\"], y=df[\"train_loss\"], name=run.stem + \".train_loss\", marker=dict(color=color), mode=\"lines\"),\n                  row=1, col=1)\n    fig.add_trace(go.Scatter(x=df[\"epoch\"], y=df[\"val_loss\"], name=run.stem + \".val_loss\", marker=dict(color=color), mode=\"lines\"),\n                  row=2, col=1)\n    fig.add_trace(go.Scatter(x=df[\"epoch\"], y=df[\"train_acc\"], name=run.stem + \".train_acc\", marker=dict(color=color), mode=\"lines\"),\n                  row=1, col=2)\n    fig.add_trace(go.Scatter(x=df[\"epoch\"], y=df[\"val_acc\"], name=run.stem + \".val_acc\", marker=dict(color=color), mode=\"lines\"),\n                  row=2, col=2)\n\nfig.update_yaxes(title_text=\"train_loss\", row=1, col=1)\nfig.update_yaxes(title_text=\"val_loss\", row=2, col=1)\nfig.update_yaxes(title_text=\"train_acc\", row=1, col=2)\nfig.update_yaxes(title_text=\"val_acc\", row=2, col=2)\nfig.update_xaxes(title_text=\"epoch\", tick0=1, dtick=1, row=2, col=1)\nfig.update_xaxes(title_text=\"epoch\", tick0=1, dtick=1, row=2, col=2)\nfig.update_layout(hovermode=\"x unified\", margin=dict(l=0, r=0, t=0, b=0))\n\nfig.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Load model","metadata":{}},{"cell_type":"code","source":"# model.load_state_dict(torch.load())\nmodel = torch.load('./models/DenseNet_230101-111116.pth')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_loss = 0\nnb_test_batches = len(test_loader)\n\nmetric = BinaryConfusionMatrix().to(device)\n\nmodel.eval()\nwith torch.no_grad():\n    for batch, (image, target) in enumerate(test_loader, start=1):\n        print(f\"Test batch progress: {batch:>3}/{nb_test_batches}\", end='\\r')\n        image = image.to(device)\n        target = target.to(device)\n        output = model(image)\n        loss = loss_fn(output, target)\n        test_loss += loss.item() * image.size(0)\n        _, preds = torch.max(output, 1)\n        metric.update(preds, target)\n\nclear_output()\ntest_loss /= len(test_loader.dataset)\nconf_matrix = metric.compute().cpu()\naccuracy = conf_matrix.diag().sum() / conf_matrix.sum()\nprint(f\"Test loss: {test_loss:.5f}\")\nprint(f\"Accuracy: {accuracy:.2%}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"normalized = True\n\nconf_matrix_normalized = conf_matrix/conf_matrix.sum(1).reshape((2,1))\n\nfig = px.imshow(\n    conf_matrix_normalized if normalized else conf_matrix,\n    text_auto=\".2%\" if normalized else True,\n    labels=dict(x=\"<b>Prediction</b>\", y=\"<b>Ground Truth</b>\"),\n    x=train_data.classes,\n    y=train_data.classes,\n    title=\"<b>Confusion matrix</b>\",\n    width=700,\n)\nfig.update_xaxes(side=\"top\")\n# fig.update_coloraxes(showscale=False)\nfig.show()\n# confusion matrix shows True Positives (TP), False Positives (FP), True Negatives (TN) and False Negatives (FN)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"cest logique davoir une meilleure accuracy sur pneumonia car le dataset possede\nbcp plus de samples avec pneumonia donc le model a appris a vraiment reconnaitre\npneumonia","metadata":{}}]}