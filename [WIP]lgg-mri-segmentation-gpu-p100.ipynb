{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Brain MRI segmentation\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat ../input/lgg-mri-segmentation/kaggle_3m/README.md"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-12-13T14:35:01.979918Z",
     "iopub.status.busy": "2022-12-13T14:35:01.978858Z",
     "iopub.status.idle": "2022-12-13T14:35:07.007617Z",
     "shell.execute_reply": "2022-12-13T14:35:07.006643Z",
     "shell.execute_reply.started": "2022-12-13T14:35:01.979882Z"
    }
   },
   "outputs": [],
   "source": [
    "from   datetime import datetime\n",
    "from   functools import reduce\n",
    "import os\n",
    "from   pathlib import Path\n",
    "import re\n",
    "\n",
    "import cv2 as cv\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from   torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torchvision.transforms as T\n",
    "import torchvision.transforms.functional as F\n",
    "from   torchvision.utils import make_grid, draw_segmentation_masks\n",
    "from   matplotlib import colors\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from   PIL import Image\n",
    "import plotly.express as px\n",
    "from   scipy.ndimage.morphology import binary_dilation\n",
    "from   skimage import io\n",
    "from   sklearn.model_selection import train_test_split\n",
    "\n",
    "from   torchmetrics import JaccardIndex, Dice\n",
    "from   sklearn.metrics import jaccard_score\n",
    "\n",
    "# bon exemple : TCGA_DU_7306\n",
    "# bon aussi car moins dexemple : TCGA_CS_5393\n",
    "\n",
    "pd.set_option('max_colwidth', 400)\n",
    "pd.set_option('display.max_rows', 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-13T14:35:07.010924Z",
     "iopub.status.busy": "2022-12-13T14:35:07.009931Z",
     "iopub.status.idle": "2022-12-13T14:35:07.028674Z",
     "shell.execute_reply": "2022-12-13T14:35:07.027497Z",
     "shell.execute_reply.started": "2022-12-13T14:35:07.010880Z"
    }
   },
   "outputs": [],
   "source": [
    "def imread(path, mode=cv.IMREAD_UNCHANGED):\n",
    "    return cv.imread(str(path), mode) / 255\n",
    "\n",
    "def mask_to_contour(mask, thickness=1, color=\"red\"):\n",
    "    \"\"\"Returns contour of binary black and white mask.\"\"\"\n",
    "    assert mask.ndim == 3, \"Mask is not RGB.\"\n",
    "    assert mask.dtype == np.float64, \"Make sure mask is in the range [0-1].\"\n",
    "    contour = reduce(lambda x, _: binary_dilation(x), [mask]*(thickness+1)) - mask\n",
    "    return contour * colors.to_rgb(color)\n",
    "\n",
    "def colored_mask(mask, color=\"red\"):\n",
    "    \"\"\"Converts a black and white mask to a colored one.\"\"\"\n",
    "    assert mask.ndim == 3, \"Mask is not RGB.\"\n",
    "    assert mask.dtype == np.float64, \"Make sure mask is in the range [0-1].\"\n",
    "    return mask * colors.to_rgb(color)\n",
    "\n",
    "# def apply_mask(img, mask, alpha=.6):\n",
    "#     \"\"\"Apply a mask to an image.\"\"\"\n",
    "#     assert img.ndim == mask.ndim == 3, \"Make sur img and mask are RGB.\"\n",
    "#     assert img.dtype == mask.dtype == np.float64, \"Make sure img and mask are in the range [0-1].\"\n",
    "#     f = np.any(mask, axis=2)\n",
    "#     t = np.stack((f,)*3, axis=-1)\n",
    "#     u = np.copy(img)\n",
    "#     temp = u + alpha * (mask - u)\n",
    "#     u[t] = temp[t]\n",
    "#     return u\n",
    "\n",
    "def apply_mask(img, mask, thickness=None, alpha=None , color=\"red\"):\n",
    "    \"\"\"mode = contour or patch\"\"\"\n",
    "    assert img.ndim == mask.ndim == 3, \"Make sur img and mask are RGB.\"\n",
    "    assert img.dtype == mask.dtype == np.float64, \"Make sure img and mask are in the range [0-1].\"\n",
    "    new_mask = np.copy(mask)\n",
    "    if thickness:\n",
    "        new_mask = reduce(lambda x, _: binary_dilation(x), [mask]*(thickness+1)) - mask\n",
    "    new_mask *= colors.to_rgb(color)\n",
    "    f = np.any(mask, axis=2)\n",
    "    t = np.stack((f,)*3, axis=-1)\n",
    "    u = np.copy(img)\n",
    "    if alpha:\n",
    "        new_mask = u + alpha * (new_mask - u)\n",
    "    u[t] = new_mask[t]\n",
    "    return u"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-13T14:35:07.031403Z",
     "iopub.status.busy": "2022-12-13T14:35:07.030568Z",
     "iopub.status.idle": "2022-12-13T14:35:08.611901Z",
     "shell.execute_reply": "2022-12-13T14:35:08.610837Z",
     "shell.execute_reply.started": "2022-12-13T14:35:07.031370Z"
    }
   },
   "outputs": [],
   "source": [
    "data_path = Path('../input/lgg-mri-segmentation/kaggle_3m/')\n",
    "\n",
    "# patients info\n",
    "data_csv = pd.read_csv(data_path/\"data.csv\")\n",
    "\n",
    "# dataset as pandas dataframe\n",
    "data_pd = pd.DataFrame([\n",
    "    (path.parts[-2], Path(str(path).replace(\"_mask\", '')), path)\n",
    "    for path in sorted(data_path.rglob(\"*_mask.tif\"),\n",
    "                       key=lambda a: ''.join(map(lambda x: f\"{x:0>2}\", re.split(r'_', a.stem))))\n",
    "], columns=[\"patient\", \"image\", \"mask\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imread2(path):\n",
    "    return cv.imread(str(path)) / 255\n",
    "\n",
    "# select random patient\n",
    "patient = np.random.choice(data_pd[\"patient\"].unique())\n",
    "\n",
    "# retrieve paths for the scans and masks of the patient\n",
    "_, imgs_path, masks_path = data_pd[data_pd[\"patient\"] == patient].T.to_numpy()\n",
    "\n",
    "# read images and masks into a list of tuples\n",
    "samples = [(imread2(img), imread2(mask)) for img,mask in zip(imgs_path, masks_path)]\n",
    "\n",
    "# list of merged image and mask next to mask\n",
    "segs = np.array([np.hstack((apply_mask(img, mask, alpha=.4), mask)) for img,mask in samples])\n",
    "\n",
    "# create slideshow\n",
    "fig = px.imshow(segs, animation_frame=0, binary_string=True, labels=dict(animation_frame=\"slice\"))\n",
    "fig.update_layout(xaxis_showticklabels=False, yaxis_showticklabels=False)\n",
    "\n",
    "# display patient info and mri\n",
    "display(data_csv.loc[data_csv['Patient'] == patient[:12]])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-13T14:35:10.125402Z",
     "iopub.status.busy": "2022-12-13T14:35:10.125026Z",
     "iopub.status.idle": "2022-12-13T14:35:10.134094Z",
     "shell.execute_reply": "2022-12-13T14:35:10.133014Z",
     "shell.execute_reply.started": "2022-12-13T14:35:10.125373Z"
    }
   },
   "outputs": [],
   "source": [
    "class BrainDataset(Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        super(BrainDataset, self).__init__()\n",
    "        self.df = df\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        _, image_path, mask_path = self.df.iloc[idx]\n",
    "#         image = imread(image_path)\n",
    "#         mask = imread(mask_path, mode=cv.IMREAD_GRAYSCALE)\n",
    "        image = io.imread(image_path)\n",
    "        mask = io.imread(mask_path)\n",
    "        if self.transform:\n",
    "            image, mask = self.transform(image), self.transform(mask)\n",
    "        return image, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-13T15:27:57.042124Z",
     "iopub.status.busy": "2022-12-13T15:27:57.041621Z",
     "iopub.status.idle": "2022-12-13T15:27:57.058260Z",
     "shell.execute_reply": "2022-12-13T15:27:57.057274Z",
     "shell.execute_reply.started": "2022-12-13T15:27:57.042082Z"
    }
   },
   "outputs": [],
   "source": [
    "# train_data, val_data, test_data = random_split(data, [.75, .15, .10], generator=torch.Generator().manual_seed(0))\n",
    "\n",
    "train_df, temp_df = train_test_split(data_pd, test_size=.25)\n",
    "val_df, test_df = train_test_split(temp_df, test_size=.4)\n",
    "\n",
    "train_transform = T.Compose([T.ToTensor(),])\n",
    "eval_transform = T.ToTensor()\n",
    "\n",
    "train_data = BrainDataset(train_df, transform=train_transform)\n",
    "val_data = BrainDataset(val_df, transform=eval_transform)\n",
    "test_data = BrainDataset(test_df, transform=eval_transform)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_data,\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    num_workers=2,\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_data,\n",
    "    batch_size=32,\n",
    "    shuffle=False,\n",
    "    num_workers=2,\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_data,\n",
    "    batch_size=32,\n",
    "    shuffle=False,\n",
    "    num_workers=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-13T14:48:02.167593Z",
     "iopub.status.busy": "2022-12-13T14:48:02.166031Z",
     "iopub.status.idle": "2022-12-13T14:48:02.674575Z",
     "shell.execute_reply": "2022-12-13T14:48:02.673564Z",
     "shell.execute_reply.started": "2022-12-13T14:48:02.167548Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/mateuszbuda_brain-segmentation-pytorch_master\n"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "model_name = \"unet\"\n",
    "device = torch.device(\"cuda\")\n",
    "model = torch.hub.load('mateuszbuda/brain-segmentation-pytorch', 'unet',\n",
    "    in_channels=3, out_channels=1, init_features=32, pretrained=True)\n",
    "model.to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "loss_fn = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-13T14:48:03.578099Z",
     "iopub.status.busy": "2022-12-13T14:48:03.577324Z",
     "iopub.status.idle": "2022-12-13T14:48:03.589652Z",
     "shell.execute_reply": "2022-12-13T14:48:03.588691Z",
     "shell.execute_reply.started": "2022-12-13T14:48:03.578059Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_loop(dataloader, optimizer, loss_fn, epoch):\n",
    "    train_loss = 0\n",
    "    model.train()\n",
    "    for batch, (image, mask) in enumerate(dataloader):\n",
    "        print(f\"[Epoch {epoch:>2}] Train batch progress: {batch+1:>3}/{len(dataloader)}\", end='\\r')\n",
    "        image = image.to(device)\n",
    "        mask = mask.to(device)\n",
    "        output = model(image)\n",
    "        loss = loss_fn(output, mask)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item() * image.size(0)\n",
    "#         break\n",
    "    return train_loss / len(dataloader.dataset)\n",
    "\n",
    "def eval_loop(dataloader, optimizer, loss_fn, epoch):\n",
    "    val_loss = 0\n",
    "    iou = 0\n",
    "#     jaccard = JaccardIndex(task=\"binary\", num_classes=2).to(device)\n",
    "    dice = 0\n",
    "#     dice = Dice(average='micro').to(device)\n",
    "    len_loader = len(dataloader.dataset)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch, (image, mask) in enumerate(dataloader):\n",
    "            print(f\"[Epoch {epoch:>2}] Val batch progress: {batch+1:>3}/{len(dataloader)}  \", end='\\r')\n",
    "            image = image.to(device)\n",
    "            mask = mask.to(device)\n",
    "            output = model(image)\n",
    "            \n",
    "            val_loss += loss_fn(output, mask).item() * image.size(0)\n",
    "            output = (output > .5).float()\n",
    "            iou += jaccard_score(mask.cpu().flatten(), output.cpu().flatten(), zero_division=1.0) * image.size(0)\n",
    "#             break\n",
    "    return (val_loss/len_loader, iou/len_loader, dice/len_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-13T14:48:10.646632Z",
     "iopub.status.busy": "2022-12-13T14:48:10.645899Z",
     "iopub.status.idle": "2022-12-13T15:10:28.173303Z",
     "shell.execute_reply": "2022-12-13T15:10:28.171903Z",
     "shell.execute_reply.started": "2022-12-13T14:48:10.646596Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch  1] Train loss: 0.03410 | Val loss: 0.03591 | Val IoU: 33.46% | Val Dice:\n",
      "[Epoch  2] Train loss: 0.02081 | Val loss: 0.01996 | Val IoU: 41.94% | Val Dice:\n",
      "[Epoch  3] Train loss: 0.01876 | Val loss: 0.02686 | Val IoU: 40.64% | Val Dice:\n",
      "[Epoch  4] Train loss: 0.01738 | Val loss: 0.02866 | Val IoU: 37.11% | Val Dice:\n",
      "[Epoch  5] Train loss: 0.01709 | Val loss: 0.01967 | Val IoU: 48.12% | Val Dice:\n",
      "[Epoch  6] Train loss: 0.01640 | Val loss: 0.01782 | Val IoU: 49.51% | Val Dice:\n",
      "[Epoch  7] Train loss: 0.01511 | Val loss: 0.01774 | Val IoU: 46.86% | Val Dice:\n",
      "[Epoch  8] Train loss: 0.01399 | Val loss: 0.01365 | Val IoU: 57.50% | Val Dice:\n",
      "[Epoch  9] Train loss: 0.01281 | Val loss: 0.02087 | Val IoU: 39.21% | Val Dice:\n",
      "[Epoch 10] Train loss: 0.01247 | Val loss: 0.01773 | Val IoU: 56.95% | Val Dice:\n",
      "[Epoch 11] Train loss: 0.01139 | Val loss: 0.01072 | Val IoU: 64.52% | Val Dice:\n",
      "[Epoch 12] Train loss: 0.01130 | Val loss: 0.01088 | Val IoU: 61.08% | Val Dice:\n",
      "[Epoch 13] Train loss: 0.01082 | Val loss: 0.01071 | Val IoU: 64.50% | Val Dice:\n",
      "[Epoch 14] Train loss: 0.01025 | Val loss: 0.01371 | Val IoU: 61.17% | Val Dice:\n",
      "[Epoch 15] Train loss: 0.01018 | Val loss: 0.01233 | Val IoU: 54.20% | Val Dice:\n",
      "[Epoch 16] Train loss: 0.00936 | Val loss: 0.01162 | Val IoU: 59.29% | Val Dice:\n",
      "[Epoch 17] Train loss: 0.00960 | Val loss: 0.01789 | Val IoU: 51.66% | Val Dice:\n",
      "[Epoch 18] Train loss: 0.00919 | Val loss: 0.01336 | Val IoU: 53.06% | Val Dice:\n",
      "[Epoch 19] Train loss: 0.00943 | Val loss: 0.00895 | Val IoU: 70.54% | Val Dice:\n",
      "[Epoch 20] Train loss: 0.00797 | Val loss: 0.00925 | Val IoU: 67.57% | Val Dice:\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, epochs+1):\n",
    "    train_loss = train_loop(train_loader, optimizer, loss_fn, epoch)\n",
    "    val_loss, iou, dice = eval_loop(val_loader, optimizer, loss_fn, epoch)\n",
    "    print(f\"[Epoch {epoch:>2}] Train loss: {train_loss:.5f} | Val loss: {val_loss:.5f} | Val IoU: {iou:.2%} | Val Dice:\")\n",
    "torch.save(model.state_dict(), model_name+'_'+datetime.now().strftime(\"%Y%m%d-%H%M%S\")+'.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-13T15:25:53.385055Z",
     "iopub.status.busy": "2022-12-13T15:25:53.384083Z",
     "iopub.status.idle": "2022-12-13T15:25:55.013100Z",
     "shell.execute_reply": "2022-12-13T15:25:55.011927Z",
     "shell.execute_reply.started": "2022-12-13T15:25:53.385002Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0157)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f5bbf34b9d0>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img,mask = next(iter(test_loader))\n",
    "print(torch.max(img[0][0][0]))\n",
    "img = img[0].unsqueeze(0)\n",
    "model.to(\"cpu\")\n",
    "res = model(img)\n",
    "res = res[0].permute((1,2,0))\n",
    "res = res.detach().numpy()\n",
    "mask = mask[0].permute((1,2,0)).detach().numpy()\n",
    "plt.imshow(mask, cmap=\"gray\")\n",
    "plt.show()\n",
    "plt.imshow(res, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread('../input/lgg-mri-segmentation/kaggle_3m/TCGA_CS_4941_19960909/TCGA_CS_4941_19960909_14.tif')\n",
    "mask = cv.imread('../input/lgg-mri-segmentation/kaggle_3m/TCGA_CS_4941_19960909/TCGA_CS_4941_19960909_14_mask.tif')\n",
    "# mask2 = cv.imread('../input/lgg-mri-segmentation/kaggle_3m/TCGA_CS_4941_19960909/TCGA_CS_4941_19960909_16_mask.tif')\n",
    "print(\"cv\", mask.shape)\n",
    "print(\"io\", mask2.shape)\n",
    "\n",
    "# a = mask_to_contour(mask/255, thickness=1)\n",
    "# a = colored_mask(mask/255, color=\"red\")\n",
    "# a = apply_mask(mask/255, mask_to_contour(mask2/255, thickness=3), alpha=.6)\n",
    "# a = apply_mask(mask/255, colored_mask(mask2/255), alpha=.5)\n",
    "a = apply_mask(img/255, colored_mask(mask/255), alpha=.7)\n",
    "# plt.imshow(mask)\n",
    "# plt.show()\n",
    "plt.imshow(a)\n",
    "plt.show()\n",
    "# plt.imshow(mask)\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
