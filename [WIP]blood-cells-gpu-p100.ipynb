{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Blood cell images\n",
    "---\n",
    "Read [homepage](https://www.kaggle.com/datasets/paultimothymooney/blood-cells) for more info.  \n",
    "From my understanding, dataset2-master is intended to classify the type of blood cell while dataset-master is intended to detect cells locations with bounding boxes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-12-20T16:18:52.875178Z",
     "iopub.status.busy": "2022-12-20T16:18:52.874279Z",
     "iopub.status.idle": "2022-12-20T16:18:58.135585Z",
     "shell.execute_reply": "2022-12-20T16:18:58.134205Z",
     "shell.execute_reply.started": "2022-12-20T16:18:52.875082Z"
    }
   },
   "outputs": [],
   "source": [
    "from   collections import OrderedDict\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('max_colwidth', 400)\n",
    "pd.set_option('display.max_rows', 50)\n",
    "from PIL import Image\n",
    "import plotly.express as px\n",
    "import torch\n",
    "assert torch.cuda.device_count() == 1, \"Select GPU P100 in Settings > Accelerator from the right panel.\"\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "# import torchvision\n",
    "# from torchvision import transforms as T\n",
    "# from torchvision.datasets import ImageFolder\n",
    "# from torchvision.utils import draw_bounding_boxes\n",
    "# from torchvision.io import read_image\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "# same bug as torchvision (cannot be imported before torchvision)\n",
    "# from torchmetrics.classification import MulticlassConfusionMatrix\n",
    "\n",
    "!nvidia-smi -L"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-20T16:18:58.140073Z",
     "iopub.status.busy": "2022-12-20T16:18:58.138393Z",
     "iopub.status.idle": "2022-12-20T16:18:58.178522Z",
     "shell.execute_reply": "2022-12-20T16:18:58.177609Z",
     "shell.execute_reply.started": "2022-12-20T16:18:58.140033Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset_master = Path(\"../input/blood-cells/dataset-master/dataset-master/\")\n",
    "dataset2_master = Path(\"../input/blood-cells/dataset2-master/dataset2-master/images/\")\n",
    "\n",
    "dataset_csv = pd.read_csv(dataset_master/\"labels.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-20T16:18:58.180949Z",
     "iopub.status.busy": "2022-12-20T16:18:58.180277Z",
     "iopub.status.idle": "2022-12-20T16:18:58.543138Z",
     "shell.execute_reply": "2022-12-20T16:18:58.542162Z",
     "shell.execute_reply.started": "2022-12-20T16:18:58.180912Z"
    }
   },
   "outputs": [],
   "source": [
    "xml_files = set(path.stem for path in dataset_master.rglob(\"*.xml\"))\n",
    "jpg_files = set(path.stem for path in dataset_master.rglob(\"*.jpg\"))\n",
    "valid_stems = sorted(xml_files.intersection(jpg_files))\n",
    "\n",
    "df = pd.DataFrame(((dataset_master/\"JPEGImages\"/(stem+\".jpg\"), dataset_master/\"Annotations\"/(stem+\".xml\")) for stem in valid_stems),\n",
    "                 columns=[\"image\", \"annotation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-20T16:18:58.545400Z",
     "iopub.status.busy": "2022-12-20T16:18:58.544904Z",
     "iopub.status.idle": "2022-12-20T16:19:14.846716Z",
     "shell.execute_reply": "2022-12-20T16:19:14.845625Z",
     "shell.execute_reply.started": "2022-12-20T16:18:58.545363Z"
    }
   },
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame(((*path.parts[-3:], path) for path in dataset2_master.rglob(\"*jpeg\")),\n",
    "                   columns=[\"subset\", \"cell_type\", \"filename\", \"path\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-20T15:46:10.221097Z",
     "iopub.status.busy": "2022-12-20T15:46:10.218584Z",
     "iopub.status.idle": "2022-12-20T15:46:10.240691Z",
     "shell.execute_reply": "2022-12-20T15:46:10.239548Z",
     "shell.execute_reply.started": "2022-12-20T15:46:10.221059Z"
    }
   },
   "outputs": [],
   "source": [
    "with pd.option_context('display.float_format', lambda x: f\"{x:.2%}\"):\n",
    "    print(df2[\"subset\"].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-20T15:46:10.244334Z",
     "iopub.status.busy": "2022-12-20T15:46:10.243650Z",
     "iopub.status.idle": "2022-12-20T15:46:10.279320Z",
     "shell.execute_reply": "2022-12-20T15:46:10.278338Z",
     "shell.execute_reply.started": "2022-12-20T15:46:10.244289Z"
    }
   },
   "outputs": [],
   "source": [
    "df2.groupby([\"cell_type\", \"subset\"]).size().unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-20T15:46:10.282497Z",
     "iopub.status.busy": "2022-12-20T15:46:10.281778Z",
     "iopub.status.idle": "2022-12-20T15:46:10.288163Z",
     "shell.execute_reply": "2022-12-20T15:46:10.287252Z",
     "shell.execute_reply.started": "2022-12-20T15:46:10.282460Z"
    }
   },
   "outputs": [],
   "source": [
    "len(df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-20T15:46:10.290046Z",
     "iopub.status.busy": "2022-12-20T15:46:10.289460Z",
     "iopub.status.idle": "2022-12-20T15:46:10.302267Z",
     "shell.execute_reply": "2022-12-20T15:46:10.301365Z",
     "shell.execute_reply.started": "2022-12-20T15:46:10.290012Z"
    }
   },
   "outputs": [],
   "source": [
    "df2.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get random sample\n",
    "img, xml = df.sample().values.flatten()\n",
    "\n",
    "root = ET.parse(xml).getroot()\n",
    "\n",
    "boxes = torch.tensor([[int(box.find(pos).text) for pos in [\"xmin\", \"ymin\", \"xmax\", \"ymax\"]] for box in root.findall(\".//bndbox\")])\n",
    "\n",
    "result = draw_bounding_boxes(read_image(str(img)), boxes, colors=[\"yellow\"]*len(boxes), width=4)\n",
    "\n",
    "plt.imshow(result.permute((1,2,0)))\n",
    "# plt.set_title()\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-20T15:41:58.076318Z",
     "iopub.status.busy": "2022-12-20T15:41:58.075843Z",
     "iopub.status.idle": "2022-12-20T15:41:58.228646Z",
     "shell.execute_reply": "2022-12-20T15:41:58.227673Z",
     "shell.execute_reply.started": "2022-12-20T15:41:58.076280Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = px.imshow(result.permute((1,2,0)))\n",
    "fig.update_xaxes(showticklabels=False)\n",
    "fig.update_yaxes(showticklabels=False)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-18T10:20:04.894798Z",
     "iopub.status.busy": "2022-12-18T10:20:04.893718Z",
     "iopub.status.idle": "2022-12-18T10:20:04.899580Z",
     "shell.execute_reply": "2022-12-18T10:20:04.898474Z",
     "shell.execute_reply.started": "2022-12-18T10:20:04.894758Z"
    }
   },
   "outputs": [],
   "source": [
    "# cat $sample | head -30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-20T16:21:10.923800Z",
     "iopub.status.busy": "2022-12-20T16:21:10.923351Z",
     "iopub.status.idle": "2022-12-20T16:21:12.275703Z",
     "shell.execute_reply": "2022-12-20T16:21:12.274572Z",
     "shell.execute_reply.started": "2022-12-20T16:21:10.923767Z"
    }
   },
   "outputs": [],
   "source": [
    "# model_name = 'densenet121'\n",
    "model_name = \"efficientnet_b4\"\n",
    "model = torch.hub.load('pytorch/vision', model_name, weights=\"DEFAULT\")\n",
    "# weight_enum = torch.hub.load(\"pytorch/vision\", \"get_model_weights\", name=\"densenet121\")\n",
    "# print([weight for weight in weight_enum])\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# # last layer de efficientnet_b7\n",
    "# model.classifier = nn.Sequential(OrderedDict([\n",
    "#     ('fcl1', nn.Linear(1024,256)),\n",
    "#     ('dp1', nn.Dropout(0.3)),\n",
    "#     ('r1', nn.ReLU()),\n",
    "#     ('fcl2', nn.Linear(256,32)),\n",
    "#     ('dp2', nn.Dropout(0.3)),\n",
    "#     ('r2', nn.ReLU()),\n",
    "#     ('fcl3', nn.Linear(32,4)),\n",
    "# ]))\n",
    "\n",
    "model.classifier = nn.Sequential(OrderedDict([\n",
    "    ('fcl1', nn.Linear(1792,256)),\n",
    "    ('dp1', nn.Dropout(0.3)),\n",
    "    ('r1', nn.ReLU()),\n",
    "    ('fcl2', nn.Linear(256,32)),\n",
    "    ('dp2', nn.Dropout(0.3)),\n",
    "    ('r2', nn.ReLU()),\n",
    "    ('fcl3', nn.Linear(32,4)),\n",
    "]))\n",
    "\n",
    "print(f\"before: {next(model.parameters()).device}\")\n",
    "device = torch.device(\"cuda\")\n",
    "model.to(device)\n",
    "print(f\"after: {next(model.parameters()).device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-20T16:21:18.014204Z",
     "iopub.status.busy": "2022-12-20T16:21:18.013813Z",
     "iopub.status.idle": "2022-12-20T16:21:19.334537Z",
     "shell.execute_reply": "2022-12-20T16:21:19.333339Z",
     "shell.execute_reply.started": "2022-12-20T16:21:18.014165Z"
    }
   },
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torchvision import transforms as T\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.utils import make_grid, draw_bounding_boxes\n",
    "from torchvision.io import read_image, ImageReadMode\n",
    "\n",
    "from torchmetrics.classification import MulticlassConfusionMatrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datasets and dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-20T16:21:19.336970Z",
     "iopub.status.busy": "2022-12-20T16:21:19.336669Z",
     "iopub.status.idle": "2022-12-20T16:21:20.983425Z",
     "shell.execute_reply": "2022-12-20T16:21:20.982437Z",
     "shell.execute_reply.started": "2022-12-20T16:21:19.336945Z"
    }
   },
   "outputs": [],
   "source": [
    "transform = T.Compose([\n",
    "    # pas besoin de resize elles ont toutes les memes dimensions\n",
    "    T.ToTensor(),\n",
    "    T.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "])\n",
    "\n",
    "train_data = ImageFolder(root=dataset2_master/\"TRAIN\", transform=transform)\n",
    "train_loader = DataLoader(\n",
    "    train_data,\n",
    "    batch_size=32,\n",
    "    num_workers=2,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "val_data = ImageFolder(root=dataset2_master/\"TEST_SIMPLE\", transform=transform)\n",
    "val_loader = DataLoader(\n",
    "    val_data,\n",
    "    batch_size=16,\n",
    "    num_workers=2,\n",
    "    shuffle=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-20T16:21:21.375847Z",
     "iopub.status.busy": "2022-12-20T16:21:21.375503Z",
     "iopub.status.idle": "2022-12-20T16:21:21.383619Z",
     "shell.execute_reply": "2022-12-20T16:21:21.382566Z",
     "shell.execute_reply.started": "2022-12-20T16:21:21.375817Z"
    }
   },
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adadelta(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-20T16:42:38.306756Z",
     "iopub.status.busy": "2022-12-20T16:42:38.306025Z",
     "iopub.status.idle": "2022-12-20T16:55:12.655217Z",
     "shell.execute_reply": "2022-12-20T16:55:12.653839Z",
     "shell.execute_reply.started": "2022-12-20T16:42:38.306719Z"
    }
   },
   "outputs": [],
   "source": [
    "epochs = 5\n",
    "for epoch in range(1, epochs+1):\n",
    "    train_loss = 0\n",
    "    nb_train_batches = len(train_loader)\n",
    "    model.train()\n",
    "    for batch, (data, target) in enumerate(train_loader):\n",
    "        print(f\"[Epoch {epoch:>2}] Train batch progress: {batch+1:>3}/{nb_train_batches}\", end='\\r')\n",
    "        data = data.to(device)\n",
    "        target = target.to(device)\n",
    "        output = model(data)\n",
    "        loss = loss_fn(output, target)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item() * data.size(0)\n",
    "    \n",
    "    val_loss = 0\n",
    "    nb_val_batches = len(val_loader)\n",
    "    val_acc = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch, (data, target) in enumerate(val_loader):\n",
    "            print(f\"[Epoch {epoch:>2}] Val batch progress: {batch+1:>3}/{nb_val_batches}\", end='\\r')\n",
    "            data = data.to(device)\n",
    "            target = target.to(device)\n",
    "            output = model(data)\n",
    "            loss = loss_fn(output, target)\n",
    "            val_loss += loss.item() * data.size(0)\n",
    "            _, preds = torch.max(output, 1)\n",
    "            val_acc += (preds == target).float().sum()\n",
    "        \n",
    "    train_loss /= len(train_loader.dataset)\n",
    "    val_loss /= len(val_loader.dataset)\n",
    "    val_acc /= len(val_loader.dataset)\n",
    "    print(f\"[Epoch {epoch:>2}] Train loss: {train_loss:.5f} | Val loss: {val_loss:.6f} | Val accuracy: {val_acc:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-20T16:56:20.454231Z",
     "iopub.status.busy": "2022-12-20T16:56:20.453794Z",
     "iopub.status.idle": "2022-12-20T16:56:20.480611Z",
     "shell.execute_reply": "2022-12-20T16:56:20.479562Z",
     "shell.execute_reply.started": "2022-12-20T16:56:20.454195Z"
    }
   },
   "outputs": [],
   "source": [
    "test_data = ImageFolder(root=dataset2_master/\"TEST\", transform=transform)\n",
    "test_loader = DataLoader(\n",
    "    test_data,\n",
    "    batch_size=32,\n",
    "    num_workers=2,\n",
    "    shuffle=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-20T16:56:20.952905Z",
     "iopub.status.busy": "2022-12-20T16:56:20.952527Z",
     "iopub.status.idle": "2022-12-20T16:56:32.301554Z",
     "shell.execute_reply": "2022-12-20T16:56:32.300096Z",
     "shell.execute_reply.started": "2022-12-20T16:56:20.952873Z"
    }
   },
   "outputs": [],
   "source": [
    "test_loss = 0\n",
    "nb_test_batches = len(test_loader)\n",
    "test_acc = 0\n",
    "metric = MulticlassConfusionMatrix(num_classes=4).to(device)\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for batch, (data, target) in enumerate(test_loader):\n",
    "        print(f\"[Epoch {epoch:>2}] Val batch progress: {batch+1:>3}/{nb_test_batches}\", end='\\r')\n",
    "        data = data.to(device)\n",
    "        target = target.to(device)\n",
    "        output = model(data)\n",
    "        loss = loss_fn(output, target)\n",
    "        test_loss += loss.item() * data.size(0)\n",
    "        _, preds = torch.max(output, 1)\n",
    "        test_acc += (preds == target).float().sum()\n",
    "        metric.update(preds, target)\n",
    "\n",
    "test_loss /= len(test_loader.dataset)\n",
    "test_acc /= len(test_loader.dataset)\n",
    "print(f\"test loss: {test_loss:.6f} | test accuracy: {test_acc:.2%}                             \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-20T16:56:42.780799Z",
     "iopub.status.busy": "2022-12-20T16:56:42.780399Z",
     "iopub.status.idle": "2022-12-20T16:56:42.792134Z",
     "shell.execute_reply": "2022-12-20T16:56:42.790926Z",
     "shell.execute_reply.started": "2022-12-20T16:56:42.780765Z"
    }
   },
   "outputs": [],
   "source": [
    "metric.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-18T11:24:59.446251Z",
     "iopub.status.busy": "2022-12-18T11:24:59.445829Z",
     "iopub.status.idle": "2022-12-18T11:24:59.453116Z",
     "shell.execute_reply": "2022-12-18T11:24:59.452201Z",
     "shell.execute_reply.started": "2022-12-18T11:24:59.446216Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data.classes\n",
    "train_data.class_to_idx"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
